{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "AI Advatars\n",
    "\n",
    "Use AI to evaluate an advertising creative against the most likely buyer personas. This colab walks you out through \n",
    "the step by step process so we can get ideas, customize them, and build your own client specific avatars\n",
    "\n",
    "1. Configure Gemini AI to drive the avatars.\n",
    "2. Star with a product description.\n",
    "3. Gemini will find the best avatars to evaluate\n",
    "4. Reliably move the avatars into Python structures\n",
    "5. Use each avatar to:\n",
    "\n",
    "a. Evaluate an existing image creative to get edit suggestions.\n",
    "b. Prioritize personas to invest in custom campaigns\n",
    "c. Get user journey insights into the persona\n",
    "d. Create an audience targeting plan for each persona.\n",
    "e. Generate keyword lists\n",
    "f. Create an effective landing page template for each avatar.\n",
    "\n",
    "1. Create summary sheet of each avatar for the campaign\n",
    "\n",
    "This is advertising specific toolkit to get started with AI and advertising creatives. Key concepts you can leverage \n",
    "in your day to day are:\n",
    "\n",
    "a. Examples of advertising prompts.\n",
    "b. Practical means of moving data from AI to Python for processing.\n",
    "c. Using Gemini for text and fir images in tandem.\n",
    "d. Building a data structure that can be fed into a Google Ads Product.\n",
    "\n",
    "Every step in this workbook builds on the last, so if we modify a step, remember to re-run the next steps in\n",
    "the sequence. To help to tune the prompts each step is designed to be run as many times that need to get the \n",
    "output to where like it. Although can use this workbook without editing code, the prompts are intended to be customized \n",
    "and evolved to the product and needs \n",
    "\n",
    "Prompts to adjust fields and content.\n",
    "Data Structures to add or remove avatars for example.\n",
    "Models the Gemini Text model is better at text, use Gemini Vision Only for images.\n",
    "Sections to add entirely new data for each avatar. \n",
    "\n",
    "Setting Expectations\n",
    "\n",
    "1. This is an AI integration, things may format incorrectly, try re-running a step if it errors on parsing.\n",
    "2. To see output may need to expand the cells.\n",
    "\n",
    "Setup\n",
    "\n",
    "Install Vertex AI SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Automatically restart kernel after installs so that your environment can access the new packages\n",
    "\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticating the notebook environment\n",
    "\n",
    "If using Colab to run this notebook, uncomment the cell below and continue. If using Vertex AI Workbench, check out the setup instructions here (https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the project ID and initialize Vertex AI SDK\n",
    "\n",
    "Get PROJECT ID using gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Define project informarion\n",
    "PROJECT_ID = \"gtech-kenjora\" # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Advatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Add Product Description To Get Avatars\n",
    "#@markdown This product description will be used to build the information\n",
    "\n",
    "product = \"mazda 3 hatchback\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Add an existing Creative to evaluate against avatars\n",
    "#@markdown This image will be evaluated by the avatars\n",
    "#@markdown Click on the folder icon on the left and upload an image, then paste the path here\n",
    "\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML, Markdown\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "def embed_image(path_to_image):\n",
    "    try:\n",
    "       img = open(path_to_image, 'rb').read()\n",
    "       return 'data:image/jpeg;base64,' + b64encode(img).decode()\n",
    "    except FileNotFoundError:\n",
    "       return ''\n",
    "\n",
    "picture_url = '/content/creative.jpg' # @param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "   picture = PIL_Image.open(picture_url)\n",
    "except OSError:\n",
    "   picture = None\n",
    "   print('WARNING: No uploaded creative detected, some parts of this workbook ay not work.')\n",
    "\n",
    "HTML(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Set Up Imports And Helpers Plus Initialize Chat\n",
    "#@markdown This just sets up common workbook functions and import necessary libraries.\n",
    "\n",
    "import re\n",
    "import json\n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "RE_LIST = re.compile(r'\n",
    "\n",
    "\n",
    "', re.DOTALL)\n",
    "RE_DICT = re.compile(r'{.*}', re.DOTALL)\n",
    "RE_HTML = re.compile(r'<.*>', re.DOTALL)\n",
    "\n",
    "def response_to_list(response):\n",
    "    return json.loads(RE_LIST.search(response.text).group(0))\n",
    "\n",
    "def response_to_dict(response):\n",
    "    try:\n",
    "      return json.loads(RE_DICT.search(response.text).group(0))\n",
    "    except json.JSONDecodeError:\n",
    "      print('Parse JSON Error:', response.text)\n",
    "\n",
    "def response_to_html(response):\n",
    "    return RE_HTML.search(response.text).group(0)\n",
    "\n",
    "model_vision = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "#model_vision = genai.GenerativeModel('gemini-pro-vision')\n",
    "model_text = GenerativeModel(\"gemini-1.0-pro\")\n",
    "#model_text = genai.GenerativeModel('gemini-pro')\n",
    "chat = model_text.start_chat(history=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1: Get A List of AI Recommended Avatars\n",
    "\n",
    "The output will be a python object, if get errors try adjusting the product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = f'Image you\\'re an agency directory running an advertising campaign for the {product}, provide descriptive\n",
    "persona names and explanations of why each is a fit.'\n",
    "\n",
    "response = response_to_list(response)\n",
    "history = chat.history\n",
    "print(json.dumps(avatars, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the creative against each avatar\n",
    "\n",
    "The output will be added to your existing PYTHON object, if you get errors try adjusting the product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if picture is None:\n",
    "   print('Go back and upload an image to the colab, then run the creative step again')\n",
    "else:\n",
    "   target_picture = Image.load_from_file(picture_url)\n",
    "   for avatar im avatars:\n",
    "       print('Running:', avatar['persona'])\n",
    "       prompt = f'Imagine you\\'re a display marketing expert, evaluate the attached image against the persona {avatar[\"persona\"]}, {avatar[\"description\"]}. List things to keep, change and suggest three ideal \n",
    "       advertising images for {avatar[\"persona\"]}:'\n",
    "       response = model_vision.generate_content(\n",
    "        contents = [f'Format your response as JSON dictionary with the keys: keep, change, sample.\\n\\n{prompt}', target_picture]\n",
    "       )\n",
    "       avatar['edits'] = response_to_dict(response)\n",
    "\n",
    "print(json.dumps(avatars, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Rank the avatars based on product fit\n",
    "\n",
    "This demonstrates how to use personas in a single prompt to generate a ranked list. This creates a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "table = '\\n'.join(f'{avatar[\"persona\"]}: {avatar[\"description\"]}' for avatar in avatars)\n",
    "prompt = f'Of the following personas, which one is most and least likely to purchase after seeing the attached advertisment, and why:\\n\\n{table}'\n",
    "response = model_vision.generate_content(\n",
    "    contents=[f'Format your response as JSON dictionary with three keys: most, least, reason.\\n\\n{prompt}', target_picture]\n",
    ")\n",
    "fit = response_to_dict(response)\n",
    "print(json.dumps(fit, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Get Audience Suggestions for each avatar\n",
    "\n",
    "Let Gemini determine which method of the targeting is the best fit for each avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "  {\n",
    "    \"title\": \"Floodlight Targeting\",\n",
    "    \"description\": \"Tracks user behavior across web, app, and ads using Google Marketing Platform's conversion tracking pixel to create tag-based audiences.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Activity-based Targeting\",\n",
    "    \"description\": \"Creates audiences based on campaign interactions or excludes users based on impression counts.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"YouTube User List Targeting\",\n",
    "    \"description\": \"Creates YouTube remarketing lists based on interactions with your videos, ads, or channel.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Customer Match Targeting\",\n",
    "    \"description\": \"Uploads customer CSV for targeting (minimum audience size of 1,000 users).\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Google Analytics 360 Audience Targeting\",\n",
    "    \"description\": \"Shares GA360 remarketing lists based on site/app behavior for targeting or building similar audiences.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Demographics Targeting\",\n",
    "    \"description\": \"Sets up ad targeting based on demographics like gender, age, parental status, and household income.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Affinity Targeting\",\n",
    "    \"description\": \"Targets users with a demonstrated interest in a specific topic.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"In-market Targeting\",\n",
    "    \"description\": \"Targets users actively researching or comparing related products and services.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Custom Audience Targeting\",\n",
    "    \"description\": \"Reaches audiences based on keywords, URLs, and apps related to your product or service.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Life Events Targeting\",\n",
    "    \"description\": \"Reaches audiences during key life events like moving, graduating, getting married, or having a baby.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Geography Targeting\",\n",
    "    \"description\": \"Targets by region (states, cities, postcodes), or specific locations (business chains, POIs, street addresses, coordinates).\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Day and Time Targeting\",\n",
    "    \"description\": \"Specifies serving ads by days and times in user or advertiser timezones.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Similar Audiences\",\n",
    "    \"description\": \"Expands existing audiences by targeting users with similar behavior and interests.\"\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"Third-party (DMP) Audiences\",\n",
    "    \"description\": \"Syncs audiences from third-party Data Management Platforms (DMPs) for more granular targeting.\"\n",
    "  }\n",
    "]\n",
    "\n",
    "table = '\\n'.join(f'{method[\"title\"]}: {method[\"description\"]}' for method in methods)\n",
    "\n",
    "for avatar in avatars:\n",
    "    print('Running:', avatar['persona'])\n",
    "\n",
    "    #preserve tokens reset history\n",
    "    chat._history = history\n",
    "\n",
    "    prompt = f'Pretend you are a marketing expert, you are selling {product} to persona {avatar[\"persona\"]}. Pick 5 audiences that will generate the most sales from the following JSON list of dictionaries:\\n\\n{table}'\n",
    "    response = chat.send_message(\n",
    "      f'Format your response as a JSON formatted list of dictionaries with quoted keys: title, description.\\n\\n{prompt}'\n",
    "    )\n",
    "    avatar['targeting'] = response_to_list(response)\n",
    "    print(json.dumps(avatar['targeting'], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Deep Funnel Analysis\n",
    "\n",
    "Use the AI to get deep funnel insights such as objections that could be addressed by the creative or the landing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for avatar in avatars:\n",
    "  print('Running:', avatar['persona'])\n",
    "\n",
    "  # preserve tokens reset history\n",
    "  chat._history = history\n",
    "\n",
    "  prompt = f'Pretend you are {avatar[\"persona\"]}. What is the most likely question you will ask about the {product} shown in the attached image.'\n",
    "  response = model_vision.generate_content(\n",
    "    contents=[f'Format your response as a plain text question without quotes.\\n\\n{prompt}', target_picture]\n",
    "  )\n",
    "  avatar['question'] = response.text.strip()\n",
    "\n",
    "  prompt = f'What response would a good sales person give to {avatar[\"persona\"]} asking a qestion about {product}. The question is:\\n\\n {avatar[\"question\"]}'\n",
    "  response = chat.send_message(\n",
    "    f'Format your response as a plain text sentence without quotes.\\n\\n{prompt}'\n",
    "  )\n",
    "  avatar['response'] = response.text.strip()\n",
    "  print(avatar['question'])\n",
    "  print(avatar['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Generate A Landing page for Each Avatar\n",
    "\n",
    "This is usually done with barnd inputs and a template but we can rely on Ai to get us close. You can use JSON to feed into an existing template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for avatar in avatars:\n",
    "  print('Running:', avatar['persona'])\n",
    "\n",
    "  # preserve tokens reset history\n",
    "  chat._history = history\n",
    "\n",
    "  prompt = f'Give me an example of a highly converting landing page for {avatar[\"persona\"]} who want to buy a {product}.  The landing page should include: Hero Section, Benefits, Social Proof, Features List, Address Objection With Response, and Call To Action. The objection to address is: {avatar[\"question\"]}. The response is: {avatar[\"response\"]}. Rephrase the obection to be more engaging to the persona.'\n",
    "  response = chat.send_message(\n",
    "    f'Format your response as a JSON dictionary.\\n\\n{prompt}'\n",
    "  )\n",
    "  avatar['page'] = response_to_dict(response)\n",
    "  print(json.dumps(avatar['page'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
