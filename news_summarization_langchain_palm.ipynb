{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News summarization with LangChain agents and Vertex AI PaLM text models\n",
    "\n",
    "Overview\n",
    "\n",
    "It is a very common practice in real-world business scenarios to integrate Large Language Models (LLMs) with external sources of knowledge or applications. In a groundbreaking paper titled Synergizing Reasoning and Acting in Language Models (https://arxiv.org/pdf/2210.03629.pdf), Google Research and Princeton University introduced a paradigm - ReAct - that combines reasoning and acting with LLMs by allowing models to interact with external environments to gather additional information.\n",
    "\n",
    "Langchain (https://python.langchain.com/docs/get_started/introduction) is a framework that allows you to create applications powered by language models. It includes extensive support for agents based on the ReAct concepts. Langchain agents use tools to interact with external systems. A tool is a component that performs a specific tasks, such as retrieving data from an external search engine. LangChain includes a number of predefined tools, such as tools for interacting with Google search, wikipedia, ArXiv, SQL databases, and many more. You can also define your own tools. \n",
    "\n",
    "This notebook illustrates how to use LangChain agents with VertexAI PaLM text models and custom tools. You will build an agent that can help you discover the most popular Google Search terms and analyze news articles related to those terms. The dataset is hosted on Google BigQuery as part of the Google Cloud Datasets initiative.\n",
    "\n",
    "The GDELT Project, which is supported by Google Jigsaw, monitors the world's broadcast, print and web news from nearly every corner of every country in over 100 languages. The GDELT database is free to use and accessible via a variety of interfaces, including Google BigQuery and the REST API. In this notebook, we will be using the REST API.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "1. You will begin by installing the necessary packages and configuring the GCP environment.\n",
    "2. Next, you will define and test the custom LangChain tools around the Google Trends dataset and the GDEL API.\n",
    "3. Finally, you will experiment with using the tools with a few different types of LangChain agents.\n",
    "\n",
    "Install pre-requisites\n",
    "\n",
    "Install the following python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -U google-cloud-aiplatform\n",
    "! pip install -U langchain\n",
    "! pip install -U python-dateutil\n",
    "! pip install -U newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT FORGET TO RESTART THE RUNTIME before continue\n",
    "\n",
    "Configure Google Cloud Environment Settings\n",
    "\n",
    "Set the following constants to reflect the GCP environment\n",
    "\n",
    "1. PROJECT_ID: Your Google Cloud Project ID\n",
    "2. REGION: The region to use for Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = '<YOUR PROJECT ID HERE>'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom LangChain tools\n",
    "\n",
    "LangChain tools allow LangChain agents to communicate with other systems. For more information on how to build and use them, please refer to the Tools getting started documentation\n",
    "\n",
    "This section of the notebook defines two custom tools:\n",
    "\n",
    "1. The Google Trends dataset tool allows an agent to retrieve a list of top-ranked search keywords on a given date.\n",
    "The tool retrieves this information from the Google Trends BigQuery dataset.\n",
    "2. The GDELT tool allows an agent to retrieve news articles that best match a set of keywords, on a given date, and with the given tone. The tool uses the GDELT API to retrieve the articles' metadata and content.\n",
    "\n",
    "There are a few options for implementing LangChain tools, including using the Tool dataclass, subclassing the BaseTool class, or using the Tool decorator. Due to the relatively complex logic, both tools are implemented by subclassing the LangChain BaseTool class.\n",
    "\n",
    "Google Trends dataset tool\n",
    "\n",
    "The tool extracts a list of the most popular search terms on a specific date with the last 30 days. The tool is a wrapper around the Google Trends Bigquery dataset. The tool expects to receive a JSON object as input, with the following format:\n",
    "\n",
    "{\n",
    "    \"date\": \"05-16-2023\"\n",
    "}\n",
    "\n",
    "Google Trends only stores the top search terms for the previous 30 days, so the date you must provide must be within the following range: [current_date - 30, current_date - 1]. If you provide a date outside of this range, the tool will return an empty list of keywords.\n",
    "\n",
    "The tool can handle a variety of data formals to account for the different ways that an LLM might return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import date, timedelta, time, datetime\n",
    "from typing import Any, Dict, List, Optional, ClassVar, Tuple\n",
    "from google.cloud import bigquery\n",
    "from dateutil.parser import parse as parse_date\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class QueryGoogleTrendsDatasetTool(BaseTool):\n",
    "       name = \"query_google_trends\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
