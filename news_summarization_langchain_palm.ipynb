{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News summarization with LangChain agents and Vertex AI PaLM text models\n",
    "\n",
    "Overview\n",
    "\n",
    "It is a very common practice in real-world business scenarios to integrate Large Language Models (LLMs) with external sources of knowledge or applications. In a groundbreaking paper titled Synergizing Reasoning and Acting in Language Models (https://arxiv.org/pdf/2210.03629.pdf), Google Research and Princeton University introduced a paradigm - ReAct - that combines reasoning and acting with LLMs by allowing models to interact with external environments to gather additional information.\n",
    "\n",
    "Langchain (https://python.langchain.com/docs/get_started/introduction) is a framework that allows you to create applications powered by language models. It includes extensive support for agents based on the ReAct concepts. Langchain agents use tools to interact with external systems. A tool is a component that performs a specific tasks, such as retrieving data from an external search engine. LangChain includes a number of predefined tools, such as tools for interacting with Google search, wikipedia, ArXiv, SQL databases, and many more. You can also define your own tools. \n",
    "\n",
    "This notebook illustrates how to use LangChain agents with VertexAI PaLM text models and custom tools. You will build an agent that can help you discover the most popular Google Search terms and analyze news articles related to those terms. The dataset is hosted on Google BigQuery as part of the Google Cloud Datasets initiative.\n",
    "\n",
    "The GDELT Project, which is supported by Google Jigsaw, monitors the world's broadcast, print and web news from nearly every corner of every country in over 100 languages. The GDELT database is free to use and accessible via a variety of interfaces, including Google BigQuery and the REST API. In this notebook, we will be using the REST API.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "1. You will begin by installing the necessary packages and configuring the GCP environment.\n",
    "2. Next, you will define and test the custom LangChain tools around the Google Trends dataset and the GDEL API.\n",
    "3. Finally, you will experiment with using the tools with a few different types of LangChain agents.\n",
    "\n",
    "Install pre-requisites\n",
    "\n",
    "Install the following python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -U google-cloud-aiplatform\n",
    "! pip install -U langchain\n",
    "! pip install -U python-dateutil\n",
    "! pip install -U newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT FORGET TO RESTART THE RUNTIME before continue\n",
    "\n",
    "Configure Google Cloud Environment Settings\n",
    "\n",
    "Set the following constants to reflect the GCP environment\n",
    "\n",
    "1. PROJECT_ID: Your Google Cloud Project ID\n",
    "2. REGION: The region to use for Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = '<YOUR PROJECT ID HERE>'\n",
    "REGION = 'us-central1'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
