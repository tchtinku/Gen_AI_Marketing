{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News summarization with LangChain agents and Vertex AI PaLM text models\n",
    "\n",
    "Overview\n",
    "\n",
    "It is a very common practice in real-world business scenarios to integrate Large Language Models (LLMs) with external sources of knowledge or applications. In a groundbreaking paper titled Synergizing Reasoning and Acting in Language Models (https://arxiv.org/pdf/2210.03629.pdf), Google Research and Princeton University introduced a paradigm - ReAct - that combines reasoning and acting with LLMs by allowing models to interact with external environments to gather additional information.\n",
    "\n",
    "Langchain (https://python.langchain.com/docs/get_started/introduction) is a framework that allows you to create applications powered by language models. It includes extensive support for agents based on the ReAct concepts. Langchain agents use tools to interact with external systems. A tool is a component that performs a specific tasks, such as retrieving data from an external search engine. LangChain includes a number of predefined tools, such as tools for interacting with Google search, wikipedia, ArXiv, SQL databases, and many more. You can also define your own tools. \n",
    "\n",
    "This notebook illustrates how to use LangChain agents with VertexAI PaLM text models and custom tools. You will build an agent that can help you discover the most popular Google Search terms and analyze news articles related to those terms. The dataset is hosted on Google BigQuery as part of the Google Cloud Datasets initiative.\n",
    "\n",
    "The GDELT Project, which is supported by Google Jigsaw, monitors the world's broadcast, print and web news from nearly every corner of every country in over 100 languages. The GDELT database is free to use and accessible via a variety of interfaces, including Google BigQuery and the REST API. In this notebook, we will be using the REST API.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "1. You will begin by installing the necessary packages and configuring the GCP environment.\n",
    "2. Next, you will define and test the custom LangChain tools around the Google Trends dataset and the GDEL API.\n",
    "3. Finally, you will experiment with using the tools with a few different types of LangChain agents.\n",
    "\n",
    "Install pre-requisites\n",
    "\n",
    "Install the following python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -U google-cloud-aiplatform\n",
    "! pip install -U langchain\n",
    "! pip install -U python-dateutil\n",
    "! pip install -U newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT FORGET TO RESTART THE RUNTIME before continue\n",
    "\n",
    "Configure Google Cloud Environment Settings\n",
    "\n",
    "Set the following constants to reflect the GCP environment\n",
    "\n",
    "1. PROJECT_ID: Your Google Cloud Project ID\n",
    "2. REGION: The region to use for Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = '<YOUR PROJECT ID HERE>'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom LangChain tools\n",
    "\n",
    "LangChain tools allow LangChain agents to communicate with other systems. For more information on how to build and use them, please refer to the Tools getting started documentation\n",
    "\n",
    "This section of the notebook defines two custom tools:\n",
    "\n",
    "1. The Google Trends dataset tool allows an agent to retrieve a list of top-ranked search keywords on a given date.\n",
    "The tool retrieves this information from the Google Trends BigQuery dataset.\n",
    "2. The GDELT tool allows an agent to retrieve news articles that best match a set of keywords, on a given date, and with the given tone. The tool uses the GDELT API to retrieve the articles' metadata and content.\n",
    "\n",
    "There are a few options for implementing LangChain tools, including using the Tool dataclass, subclassing the BaseTool class, or using the Tool decorator. Due to the relatively complex logic, both tools are implemented by subclassing the LangChain BaseTool class.\n",
    "\n",
    "Google Trends dataset tool\n",
    "\n",
    "The tool extracts a list of the most popular search terms on a specific date with the last 30 days. The tool is a wrapper around the Google Trends Bigquery dataset. The tool expects to receive a JSON object as input, with the following format:\n",
    "\n",
    "{\n",
    "    \"date\": \"05-16-2023\"\n",
    "}\n",
    "\n",
    "Google Trends only stores the top search terms for the previous 30 days, so the date you must provide must be within the following range: [current_date - 30, current_date - 1]. If you provide a date outside of this range, the tool will return an empty list of keywords.\n",
    "\n",
    "The tool can handle a variety of data formals to account for the different ways that an LLM might return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datetime import date, timedelta, time, datetime\n",
    "from typing import Any, Dict, List, Optional, ClassVar, Tuple\n",
    "from google.cloud import bigquery\n",
    "from dateutil.parser import parse as parse_date\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class QueryGoogleTrendsDatasetTool(BaseTool):\n",
    "       name = \"query_google_trends\"\n",
    "       description = \"\"\"Useful for when you need to find top search terms on a given date.\n",
    "       Input is a JSON object that has the field date.\n",
    "       The date must be in the following format: YYYY-MM-DD.\n",
    "       \"\"\"\n",
    "\n",
    "       client: Any\n",
    "       project_id: str\n",
    "       location: str = 'US'\n",
    "\n",
    "       def _retrieve_top_terms(self, date:str):\n",
    "           \"\"\"retrieves top terms from BigQuery for a given data.\"\"\"\n",
    "\n",
    "           query = f\"\"\"SELECT term, rank FROM `bigquery-public-data.google_trends.top_terms`\n",
    "                WHERE refresh_date = '{date}'\n",
    "                GROUP BY 1,2\n",
    "                ORDER BY rank ASC\n",
    "                \"\"\"\n",
    "           query_job = self.client.query(\n",
    "            query=query,\n",
    "            location=self.location\n",
    "           )\n",
    "           df=query_job.to_dataframe()\n",
    "           return df\n",
    "\n",
    "       def _parse_date(self, json_params_str: str):\n",
    "          \"\"\"Retrieves a date from the JSON input parameters\n",
    "          and normalizes it to the format required by BigQuery.\"\"\"\n",
    "\n",
    "          params = json.loads(json_params_str)\n",
    "\n",
    "          if 'date' in params:\n",
    "             try:\n",
    "                dt = parse_date(params['date'])\n",
    "                dt = dt.date()\n",
    "             except:\n",
    "                dt = date.today()\n",
    "\n",
    "          else:\n",
    "               dt = date.today()\n",
    "          \n",
    "          if dt >= date.today() or dt <= date.today() - timedelta(days=30):\n",
    "             dt_str = \"\"\n",
    "          else:\n",
    "             dt_str = dt.strftime('%Y-%m-%d')\n",
    "\n",
    "          return dt_str\n",
    "\n",
    "       def _run(self, json_params_str: str):\n",
    "           \"\"\"Return top search terms as a JSON list\"\"\"\n",
    "\n",
    "           refresh_date = self._parse_date(json_params_str)\n",
    "           terms = json.dumps([])\n",
    "           if refresh_date:\n",
    "              df = self._retrieve_top_terms(refresh_date)\n",
    "              if not df.empty:\n",
    "                 terms = df.loc[0].values[0]\n",
    "                 terms = json.dumps(terms.split(' '))      \n",
    "\n",
    "           return terms\n",
    "\n",
    "       def _arun(self, json_params: str):\n",
    "           raise NotImplementedError(\"This tool does not support async\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "google_trends_tool = QueryGoogleTrendsDatasetTool(\n",
    "    project_id=PROJECT_ID,\n",
    "    client=bigquery.Client(project=PROJECT_ID)\n",
    ")\n",
    "date_str = (date.today() - timedelta(days=10)).strftime('%Y-%m-%d')\n",
    "input_params = f'{{\"date\": \"{date_str}\"}}'\n",
    "google_trends_tool.run(input_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDELT Search tool\n",
    "\n",
    "The GDELT Search tool enables an agent to obtain information about articles that match a set of keywords. The tool takes a JSON object as input, with the following format:\n",
    "\n",
    "{\n",
    "    \"date\": \"05-16-2023\",\n",
    "    \"keywords\": [\"Real\", \"Madrid\"],\n",
    "    \"tone\": \"positive\"\n",
    "\n",
    "}\n",
    "\n",
    "The tool will search for articles published between dates date - time_window_dates and date + time_window_days, where time_window_days is configurable parameter. The tone field can be either positive, negative or unknown. Please refer GDELT Documentation (https://blog.gdeltproject.org/gdelt-doc-2-0-api-debuts/#:~:text=theme%3ATERROR-,Tone,-.%20Allows%20you%20to) for more information on the tone setting. We define positive as a tone value greater than 5 and negative as tone value less than 5. If the tone field is set to unknown, it will not be used in GDELT API query.\n",
    "\n",
    "Beside the time_window, there are other configuration parameters that control the results, including the maximum number of returned records (max_records) and the maximum distance between the keywords in an article (n_near_words)\n",
    "\n",
    "The tool returns a text that is a compilation of article titles and article summaries for the found articles\n",
    "\n",
    "The tool is made up of 2 components\n",
    "\n",
    "1. A retriever that searches for articles that match the input and retrieves the metadata and content of the articles. It uses the GDELT 2.0 DOC API and is implemented as a LangChain retriever.\n",
    "2. A summarizer that is a LangChain LLM chain that summarizes the content of the articles.\n",
    "\n",
    "The tool first runs the retriever to get a list of LangChain documents with the content and metadata of the articles. It then runs the summarizing chain on each article content to create a list of summaries. Finally, it combines the article titles and the summarizes into a single piece of text to return as an output.\n",
    "\n",
    "Let's start by defining the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "from newspaper import ArticleException\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "\n",
    "class GDELTRetriever(BaseRetriever):\n",
    "      gdelt_api_url: ClassVar[str]='https://api.gdeltproject.org/api/v2/doc/doc'\n",
    "      mode: str='ArtList'\n",
    "      format: str='json'\n",
    "      max_records: int=10\n",
    "      n_near_words: int=50\n",
    "      source_country: str='US'\n",
    "      source_lang: str='english'\n",
    "      time_window_days: int=3\n",
    "\n",
    "\n",
    "      def _get_articles_info(self, keywords: str, startdatetime: datetime, enddatetime: datetime, tone: str) -> Dict:\n",
    "          \"\"\"Retrieves article links and article metadata from GDELT API\"\"\"\n",
    "          startdatetime_str = startdatetime.strftime('%Y%m%d%H%M%S')\n",
    "          enddatetime_str = enddatetime.strftime('%Y%m%d%H%M%S')\n",
    "          if tone == 'positive':\n",
    "             tone = 'tone>5'\n",
    "          elif tone == 'negative':\n",
    "              tone = 'tone<-5'\n",
    "          else:\n",
    "              tone = ''\n",
    "\n",
    "          query = f'near{self.n_near_words}:\"{keywords}\"'\n",
    "          query += f'sourcecountry:{self.source_country} source_lang:{self.source_lang}'\n",
    "          if tone:\n",
    "             query += f'{tone}'\n",
    "          else:\n",
    "             query += query[:-1] \n",
    "          params = {\n",
    "            'query': query,\n",
    "            'format': self.format,\n",
    "            'mode': self.mode,\n",
    "            'maxrecords': str(self.max_records)\n",
    "            'startdatetime': startdatetime_str,\n",
    "            'enddatetime': enddatetime_str\n",
    "          }\n",
    "          response = requests.get(self.gdelt_api_url, params=params)\n",
    "          response.raise_for_status()\n",
    "          return response.json()\n",
    "\n",
    "      def _parse_article(self, url: str) -> str:\n",
    "          \"\"\"Retrieves and scrapes an article from a given URL.\"\"\"\n",
    "          article = Article(url)\n",
    "\n",
    "          try:\n",
    "              article.download()\n",
    "              article.parse()\n",
    "          except ArticleException:\n",
    "              return \"\"\n",
    "          else:\n",
    "              return article.text\n",
    "\n",
    "      def _get_documents(self, articles: Dict) -> List[Document]:\n",
    "          \"\"\"Converts a list of articles into a list of LangChain documents.\"\"\"\n",
    "          documents = []\n",
    "          unique_docs = set()\n",
    "\n",
    "          if not articles:\n",
    "             return documents\n",
    "\n",
    "          for article in articles['articles']:\n",
    "              parsed_article = self._parse_article(article['url'])\n",
    "              if parsed_article and (article['title'] not in unique_docs):\n",
    "                 unique_docs.add(article['title'])\n",
    "                 document=Document(\n",
    "                    page_content=parsed_article,\n",
    "                    metadata={\n",
    "                        'title': article['title'],\n",
    "                        'url': article['url'],\n",
    "                        'domain': article['domain'],\n",
    "                        'date': article['seendate']\n",
    "                    }\n",
    "                 )\n",
    "                 documents.append(document)\n",
    "          return documents\n",
    "    \n",
    "      def _get_documents(self, articles: Dict) -> List[Document]:\n",
    "          \"\"\"Converts a list of articles into a list of LangChain documents.\"\"\"\n",
    "          documents = []\n",
    "          unique_docs = set()\n",
    "\n",
    "          if not articles:\n",
    "             return documents\n",
    "\n",
    "          for article in articles['articles']:\n",
    "              parsed_article = self._parse_article(article['url'])\n",
    "              if parsed_article and (article['title'] not in unique_docs):\n",
    "                 unique_docs.add(article['title'])\n",
    "                 document = Document(\n",
    "                    page_content=parsed_article,\n",
    "                    metadata={\n",
    "                        'title': article['title'],\n",
    "                        'url': article['url'],\n",
    "                        'domain': article['domain'],\n",
    "                        'date': article['seendate']\n",
    "                    }\n",
    "                 ) \n",
    "                 documents.append(document)\n",
    "          return documents\n",
    "\n",
    "      def get_relevant_documents(self, query: str, filters: Optional[Dict[str, object]] = None) -> List[Document]:\n",
    "          \"\"\"Retrieves relevant documents from GDELT API for a given query.\"\"\"\n",
    "\n",
    "          if filters and filters.get('date'):\n",
    "             event_date = filters['date']\n",
    "\n",
    "          else:\n",
    "             event_date = date.today()\n",
    "          if filters and filters.get('tone'):\n",
    "             tone = filters['tone']\n",
    "          else:\n",
    "             tone = ''\n",
    "          startdatetime = datetime.combine(event_date - timedelta(days=self.time_window_days), datetime.min.time())\n",
    "          enddatetime = datetime.combine(event_date + timedelta(days=self.time_window_days), datetime.min.time())\n",
    "          articles = self._get_articles_info(query, startdatetime, enddatetime, tone)\n",
    "          documents = self._get_documents(articles)\n",
    "\n",
    "          return documents\n",
    "\n",
    "      async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "            raise NotImplementedError(\"Async interface to GDELT not implemented\") \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run a quick test on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "retriever = GDELTRetriever(max_records=5)\n",
    "\n",
    "keywords = \"Seattle Seahawks\"\n",
    "filters = {\n",
    "    \"date\": date(2022, 2, 2),\n",
    "    \"tone\": \"positive\"\n",
    "}\n",
    "articles = retriever.get_relevant_documents(\n",
    "    query=keywords,\n",
    "    filters=filters\n",
    ")\n",
    "\n",
    "for article in articles:\n",
    "    print(article.page_content[0:300])\n",
    "    pp.print(article.metadata)\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the LangChain tool, which encapsulates the retriever and the summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dateutil.parser import parse as parse_date\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.base import BasePromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class GDELTSearchTool(BaseTool):\n",
    "      name = \"gdelt_search\"\n",
    "      description = \"\"\"\n",
    "      Useful for when you need to find news or articles matching a list of terms.\n",
    "      Input is a JSON object that has a date, keywords, and tone fields.\n",
    "      The keywords field is a JSON list of terms to use for search.\n",
    "      The date field is a date to use for search. The date format is YYYY-MM-DD.\n",
    "      The tone field can be positive, negative or unknown. If you are not sure what the tone is use unknown.\n",
    "      \"\"\"\n",
    "\n",
    "      failed_to_retrieve_message: str = \"Could not retrieve any articles\"\n",
    "\n",
    "      gdelt_retriever: GDELTRetriever\n",
    "      summarize_chain: LLMChain\n",
    "\n",
    "      def _parse_params(self, json_params_str: str) -> [str, dict]:\n",
    "          \"\"\"Parse input parameters\"\"\"\n",
    "          query = \"\"\n",
    "          filters = {}\n",
    "\n",
    "          params = json.loads(json_params_str)\n",
    "\n",
    "          if ('keywords' in params) and (isinstance(params['keywords'], list)):\n",
    "              query = ' '.join(params['keywords'])\n",
    "\n",
    "          if 'date' in params:\n",
    "              filters['date'] = parse_date(params['date']).date()\n",
    "\n",
    "          if 'tone' in params and params['tone'] in ['positive', 'negative']\n",
    "              filters['tone'] = params['tone']\n",
    "\n",
    "          return query, filters\n",
    "\n",
    "      def _summarize_articles(self, articles: List[Document]) -> List[str]:\n",
    "          summaries = []\n",
    "          for article in articles\n",
    "              summary = self.summarize_chain.run(article.page_content[0:self.max_words])\n",
    "              summaries.append(summary)\n",
    "          return summaries\n",
    "\n",
    "      def _prepare_output(self, articles: List[Document], summaries: List[str]) -> str:\n",
    "         \"\"\"Prepare output returned by the tool.\"\"\"\n",
    "\n",
    "         response = \"\"\n",
    "         for document, summary in zip(articles, summaries):\n",
    "             record = f\"\"\"\n",
    "             ------------------------------\n",
    "             Article title: {document.metadata['title']}\n",
    "             Article summary: {summary}\"\"\"\n",
    "             response += record\n",
    "\n",
    "         return response\n",
    "\n",
    "      def _arun(self, json_params: str):\n",
    "          raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create and instance of the tool and run a quick test\n",
    "\n",
    "First you need to create a summarizing LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name='text-bison@001',\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.0,\n",
    "    top_p=0,8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"Write a brief summmary of the following articles:\n",
    "\n",
    "Article:\n",
    "{article}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"article\"])\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the instance of the GDELT retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "retriever = GDELTRetriever(max_records=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the retriever and the summarizing chain to create an instance of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gdelt_tool = GDELTSearchTool(summarize_chain=llm_chain, gdelt_retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the test let's search for news about Seattle Seahawks that were published around the 3rd February 2023 \n",
    "and had a positive tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(gdelt_tool._run('{\"keywords\": [\"Seattle\", \"Seahawks\"], \"date\": \"2023-02-03\", \"tone\": \"positive\"}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool returned a single piece of text that compiles article titles and article summaries of all matched articles.\n",
    "\n",
    "We now have all the components required to experiment with LangChain agents\n",
    "\n",
    "Experiment with LangChain agents\n",
    "\n",
    "Let's start with a zero-shot-react-description agent.\n",
    "\n",
    "A zero-shot-react-description agent is the type of an agent that only acts on the current request and has no memory. It is based on the ReAct framework and uses ReAct style prompts when comunicating with an LLM. It decides which tool to use to perform an action solely based on the tool's description, so finding the correct description \n",
    "of the tool is critical to the agent's performance.\n",
    "\n",
    "Note:\n",
    "\n",
    "LLMs are not aware of the current date. As a result, if you use relative time references (e.g, yesterdy, two todays from now, etc. ) in your interactions, they will hallucinate the current date. This can be addressed by configuring the agent to use yet another external tool, but here we will use absolute date references in the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [google_trends_tool, gdelt_tool]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, intermediate_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the default llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt, as you can see, merges the tool descriptions from the tools we defined earlier in the notebook with the ReAct style instructions.\n",
    "\n",
    "Let's now run a few queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agent(\"What were the top news on November 13th 2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent utilized the Google Trends tool to obtain the response. Note how the agent properly formatted the input to the tool as a JSON Object"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
