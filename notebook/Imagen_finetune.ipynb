{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tune Imagen Model\n",
    "\n",
    "Overview\n",
    "\n",
    "Imagen model is a text to image model from Google AI, trained on massive dataset of images. You can generate images for different scenarios such as ads, photo shoots, blog post images, and etc. Sometimes, we want to personalize the models to achieve our goals.We can fine tune Imagen by using 5-10 images to do that\n",
    "\n",
    "The notebook is structured as follows\n",
    "1. We check all the prerequisites to make sure we have all the gcp resources ready for fine tuning\n",
    "2. Then will see how to kick off an imagen fine-tuning pipeline\n",
    "3. After the pipeline get kicked off, will see how to poll the job state\n",
    "4. Once the job successfully finishes running, we will see how to get the fine-tuned model endpoint.\n",
    "5. In the end, we will see how to generate imagesby querying the fine-tuned model\n",
    "\n",
    "Pre-requisites\n",
    "\n",
    "Quota Check: If we don't have enough, go to Quotas page and increase quota for the following metric and region:\n",
    "metric:aiplatform.googleapis.com/restricted_image_training_a2_cpus and region:us-east4\n",
    "\n",
    "Training Images setup:\n",
    "Create a Cloud Storage bucket. Upload local files to the Cloud Storage bucket (JPEG, PNG, GIF or BMP files)\n",
    "\n",
    "Create a CSV input file that lists the Cloud storage location of the fine-tuning images.\n",
    "\n",
    "Performance & Limitations:\n",
    "\n",
    "Maximum fine-tuning training file size: 10MB\n",
    "Concurrent fine-tuning subjects per project: 1\n",
    "Generate API calls(prompts per minute per project): 5\n",
    "Fine-tune a subject model: up to 120 minutes\n",
    "Generate request: up to 20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune it for a specific subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "DISPLAY_NAME = ''\n",
    "GCS_OUTPUT_DIR = ''\n",
    "SUBJECT_ID = ''\n",
    "CLASS_NAME = ''\n",
    "PROJECT_ID = ''\n",
    "IMAGE_CSV_URI = ''\n",
    "LOCATION = \"\"\n",
    "DEPLOYMENT_REPLICA_COUNT =  #It's an integer not string\n",
    "SERVICE_ACCOUNT = ''\n",
    "TEMPLATE_URI = \"\"\n",
    "BEAR_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"displayName\": DISPLAY_NAME,\n",
    "    \"runtimeConfig\": {\n",
    "        \"gcsOutputDirectory\": GCS_OUTPUT_DIR,\n",
    "        \"parameterValues\": {\n",
    "            \"subject_id\": SUBJECT_ID,\n",
    "            \"class_name\": CLASS_NAME,\n",
    "            \"project\": PROJECT_ID,\n",
    "            \"image_csv_uri\": IMAGE_CSV_URI,\n",
    "            \"location\": LOCATION,\n",
    "            \"deployment_replica_count\": DEPLOYMENT_REPLICA_COUNT\n",
    "        }\n",
    "    },\n",
    "    \"templateUri\": TEMPLATE_URI,\n",
    "    \"serviceAccount\": SERVICE_ACCOUNT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "json_payload = json.dumps(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "url = f'https://{LOCATION}-aiplatform.googlepis.com/ui/projects/{PROJECT_ID}/locations/{LOCATION}/pipelineJobs'\n",
    "headers = {'content-type': 'application/json', 'charset': 'UTF-8', 'Authorization': BEAR_TOKEN}\n",
    "try:\n",
    "   r = requests.post(url, data=json_payload, headers=headers)\n",
    "   print(r.json())\n",
    "   res = r.json()\n",
    "   pipelinejob_id = res['name'].split('/')[-1]\n",
    "except Exception as e:\n",
    "   print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll Job States (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "url = f'https://{LOCATION}-aiplatform.googlepis.com/ui/projects/{PROJECT_ID}/locations/{LOCATION}/pipelineJobs/{pipelinejob_id}'\n",
    "headers = {'Authorization': BEAR_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "   r_pipeline_job = requests.get(url, headers=headers)\n",
    "   r_pipeline_job.json()\n",
    "   job_state = r_pipeline_job.json()['state']\n",
    "   print(f\"pipeline job state: {job_state}\")\n",
    "except Exception as e:\n",
    "   print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the fine-tuned model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "   r_completed_pipeline_job = requests.get(url, headers=headers)\n",
    "   res = r_completed_pipeline_job.json()\n",
    "   endpoint_id = res['output']['endpoint_resource_name']\n",
    "except Exception as e:\n",
    "   print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_one = open(\"res_output.txt\", \"w\")\n",
    "str_val = str(res)\n",
    "file_one.write(str_val.replace(\",\", \"\\n\"))\n",
    "file_one.close()\n",
    "patrn = \"output:endpoint_resource_name\"\n",
    "file_one = open(\"res_output.txt\", \"r\")\n",
    "\n",
    "for line in file_one:\n",
    "    if re.search(patrn, line):\n",
    "       if 'stringValue' not in line:\n",
    "           LOCATION = line.split('\\')[-2].split(\"/\")[-3]\n",
    "           print(LOCATION)\n",
    "           endpoint_id = line.split('\\')[-2].split(\"/\")[-1]\n",
    "           print(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Images from the fine-tuned model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_PROMPT = 'a stock photo of [diorperfume] perfume bottle on beach with beautiful sunset in background, cinematic, 8k, highly detailed, amazon.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "finetuned_model_payload = {\n",
    "    \"instances\": [\n",
    "       {\n",
    "         \"prompt\": TEXT_PROMPT\n",
    "       } \n",
    "    ],\n",
    "    \"parameters\": {\n",
    "        \"sampleCount\": IMAGE_COUNT\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "json_finetuned_model_payload = json.dumps(finetuned_model_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "url = f'https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{endpoint_id}:predict'\n",
    "headers = {'content-type': 'application/json', 'charset': 'UTF-8', 'Authorization': BEAR_TOKEN}\n",
    "try:\n",
    "   r_generated_images = requests.post(url, data=json_finetuned_model_payload, headers=headers)\n",
    "except Exception as e:\n",
    "   print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "predict_list = r_generated_images.json()['predictions']\n",
    "c=0\n",
    "for image in predict_list:\n",
    "    imgdata = base64.b64decode(image['bytesBase64Encoded'])\n",
    "    filename = f'perfume{c}.jpg'\n",
    "    with open(filename, 'wb') as f:\n",
    "         f.write(imgdata)\n",
    "    display(Image(filename=f'perfume{c}.jpg'))\n",
    "    c+=1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
