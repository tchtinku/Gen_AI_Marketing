{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand Voice using Tuned foundation model\n",
    "\n",
    "Your brand's voice is its soul - the way it speaks to the world. This nptebook will become your essential toolkit for crafting and refining\n",
    "a distinct voice of the brand for all your content creation efforts. It's designed to be a living document, guiding you in translating \n",
    "abstract brand values into tangible communication\n",
    "\n",
    "On Vertex AI, tuning allows you to customize a foundation model for more specific tasks or knowledge domains.\n",
    "\n",
    "While the prompt design is excellent for quick experimentation, if training data (examples) is available, tuning a model enables you to\n",
    "customize the model for the characteristics of brand you want to project\n",
    "\n",
    "Objective\n",
    "\n",
    "This tutorial teaches you how to tune a foundation model on new unseen data and you will use the following google cloud products:\n",
    "    1. Vertex AI Generative AI Studio\n",
    "    2. Vertex AI pipelines\n",
    "    3. Vertex AI model registry\n",
    "    4. Vertex AI Endpoints\n",
    "    \n",
    "This steps performed include \n",
    "    1. Upload training data \n",
    "    2. Create a pipeline job\n",
    "    3. Inspect your model on Vertex AI Model Registry\n",
    "    4. Get predictions from your tuned model\n",
    "    \n",
    "    \n",
    "Quota\n",
    "\n",
    "important: Tuning the text-bison@002 model uses the tpu-v3-8 training resources and the accompanying quotas rom your google\n",
    "Cloud project. Each project has a default quota of eight v3-8 cores, which allows for one to two concurrent tuning jobs. If you want to run more concurrent jobs you need\n",
    "to run more concurrent jobs you need to request additional quota via Quotas page\n",
    "\n",
    "Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "    \n",
    "    1. Vertex AI Generative AI Studio\n",
    "    \n",
    "Learn about Vertex AI pricing and use the Pricing Calculator to generate a cost estimate based on the projected usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticating the notebook environment\n",
    "\n",
    "1. while using colab, uncomment the cell below & then continue\n",
    "2. While using Vertex AI Workbench, check instruction in https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the Project ID\n",
    "\n",
    "Update project ID using gcloud or use https://support.google.com/googleapi/answer/7014113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"GOOGLE_CLOUD_PROJECT_HERE\"\n",
    "\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bucket\n",
    "\n",
    "Now we have to create the bucket that we will store the tuning data. To avoid name collissions b/w users on\n",
    "resources created, generate a UUID for each instance session and append it to the name of the resources \n",
    "created in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "#Generate a uuid of a specified length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a bucket name and update BUCKET_NAME parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"genai-mkt-dev/tune-dataset\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"<BUCKET_NAME>\":\n",
    "    BUCKET_NAME = \"vertex-\" + UUID\n",
    "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only if the bucket doesn't already exist: Run the following cell to create Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally validate access to the Cloud Storage bucket by examining its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -a1 $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "\n",
    "Colab only: Run the cell to initialize the Vertex AI SDK. In Vertex AI, it isn't required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the Model\n",
    "\n",
    "Now it's time to create a tuning job. Tune a foundation modelby creating a pipeline job using Generative AI Studio, cURL, or the Python SDK. Here we will be using Python SDK. We will be using a Q&A with a context dataset in JSON format\n",
    "\n",
    "Training Data\n",
    "\n",
    "Your model tuning dataset must be a JSONL format where each line ontains a single training example. You must make \n",
    "sure that you include instructions\n",
    "\n",
    "Upload to cloud storage bucket and add filenames below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = \"tune_data_brand_voice.json1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data_filename = \"tune_eval_data_brand_voice.json1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check to make sure that the files are available in your Google cloud storage bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -a1 $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_URI = f\"${BUCKET_URI}/{training_data_filename}\"\n",
    "EVALUATION_DATA_URI = f\"${BUCKET_URI}/{evaluation_data_filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Tuning\n",
    "\n",
    "Now it's time to tune a model. You will use the Vertex AI SDK to submit our tuning job.\n",
    "\n",
    "Recommended Tuning Configurations\n",
    "\n",
    "Extractive QA:\n",
    "1. Make sure that train dataset size is 100+\n",
    "2. Training steps[100-500]. Can try more than one value to get the best performance on a particular dataset (e.g 00, 200, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = \"Adapter Tuning Voice - \"\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name = display_name,\n",
    "    project = PROJECT_ID,\n",
    "    location = REGION\n",
    ")\n",
    "\n",
    "print(tensorboard.display_name)\n",
    "print(tensorboard.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_id = tensorboard.resource_name.split(\"tensorboards/\")[-1]\n",
    "print(tensorboard_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"genai-tuned-model-{UUID}\"\n",
    "TRAINING_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"model_display_name\": MODEL_NAME,\n",
    "    \"location\": REGION,\n",
    "    \"large_model_reference\": \"text-bison@002\",\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"train_steps\": TRAINING_STEPS,\n",
    "    \"dataset_uri\": TRAINING_DATA_URI,\n",
    "    \"evaluation_interval\": 20,\n",
    "    \"evaluation_data_uri\": EVALUATION_DATA_URI,\n",
    "    \"tensorboard_resource_id\": tensorboard_id\n",
    "}\n",
    "\n",
    "pipeline_root = f\"{BUCKET_URI}/{MODEL_NAME}\"\n",
    "template_path = \"https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuned_model(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    template_path: str,\n",
    "    model_display_name: str,\n",
    "    pipeline_arguments: str,\n",
    "):\n",
    "    \"\"\"Prompt-tune a new model, based on a prompt-response data.\n",
    "    \n",
    "    \"training_data\" can be either the GCS URI of a file formatted in JSONL format\n",
    "    (for example: training_data=f'gs://{bucket}/{filename}.jsonl'), or a pandas\n",
    "    DataFrame. Each training example should be JSONL record with 2 keys, for \n",
    "    example:\n",
    "       {\n",
    "           \"input_text\": <input_prompt>,\n",
    "           \"output_text\": <associated output>\n",
    "       },\n",
    "       \n",
    "    Args:\n",
    "       project_id: GCP project ID, used to initialise aiplatform\n",
    "       location: GCP region, used to initialise aiplatform\n",
    "       template_path: path to the template\n",
    "       model_display_name: Name for your model\n",
    "       pipeline_arguments: arguments used during pipeline runtime\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    aiplatform.init(project=project_id, location=location)\n",
    "    \n",
    "    from google.cloud.aiplatform import PipelineJob\n",
    "    \n",
    "    job = PipelineJob(\n",
    "        template_path=template_path,\n",
    "        display_name=model_display_name,\n",
    "        parameter_values=pipeline_arguments,\n",
    "        location=REGION,\n",
    "        pipeline_root=pipeline_root,\n",
    "        enable_caching=True\n",
    "    )\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's time to start tuning the job\n",
    "\n",
    "DISCLAIMER: tuning and deploying a model takes time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = tuned_model(PROJECT_ID, REGION, template_path, MODEL_NAME, pipeline_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following link above, you can view your pipeline run. As you can see in the screenshot below, it will execute the following steps\n",
    "\n",
    "1. Validation\n",
    "2. Export managed dataset\n",
    "3. Convert JSONL to TFRecord\n",
    "4. Large language model tuning\n",
    "5. Upload LLM model\n",
    "\n",
    "job.state let's you check the state of your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View your tuned foundational model on vertex AI model registry\n",
    "\n",
    "When your tuning job is finished, your model will be available on Vertex AI Model registry. The following Python SDK sample shows you how to list tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tuned_models(project_id, location):\n",
    "    aiplatform.init(project=project_id, location=location)\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    tuned_model_names = model.list_tuned_model_names()\n",
    "    print(tuned_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tuned_models(PROJECT_ID, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the Google Cloud Console UI to view all of your model in Vertex AI Model Registry. Below you can see an example of a tuned foundational model available on Vertex AI Model Registry.\n",
    "\n",
    "Use your tuned model to get predictions\n",
    "\n",
    "Now it's time to get predictions. First you need to get the latest tuned model from the Vertex AI Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_model(project_id, location):\n",
    "    aiplatform.init(project=project_id, location=location)\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    list_tuned_models = model.list_tuned_model_names()\n",
    "    tuned_model = list_tuned_models[0]\n",
    "    \n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = fetch_model(PROJECT_ID, REGION)\n",
    "deployed_model = TextGenerationModel.get_tuned_model(deployed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start send a prompt to the API. Feel free to update the following prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Theme: Sales of new women's handbags at Cymbal\\nUsing the Brand Voice, generate a personalized email with the theme mentioned above for the user \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deployed_model.predict(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "print(foundation_model.predict(PROMPT))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
